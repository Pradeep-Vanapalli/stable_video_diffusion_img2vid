# stable_video_diffusion_img2vid
* We can generate the videos by giving the image as an input. It generates the 20-24 frames and combine them to generate the video.

## References : 
- https://huggingface.co/stabilityai/stable-video-diffusion-img2vid
- https://colab.research.google.com/github/mkshing/notebooks/blob/main/stable_video_diffusion_img2vid.ipynb
- https://www.youtube.com/watch?v=76-qRyJwqrI&t=11s
